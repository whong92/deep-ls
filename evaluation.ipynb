{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB_MODE = False\n",
    "SETUP_RUNTIME = False\n",
    "# google colab shenanigans\n",
    "if COLAB_MODE:\n",
    "    if SETUP_RUNTIME:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive')\n",
    "        !pip install torch==1.11.0\n",
    "        !mkdir /content/data\n",
    "        !rsync --progress /content/drive/MyDrive/colab_data/deep-ls/old-tsp-data.tar.gz /content/data\n",
    "        !tar -xzvf data/old-tsp-data.tar.gz -C /content/data/\n",
    "\n",
    "        !git clone https://github.com/whong92/deep-ls.git\n",
    "        %cd deep-ls\n",
    "        !git checkout greedy_postproc\n",
    "    else:\n",
    "        %cd deep-ls\n",
    "\n",
    "    data_root = '/content/data/tsp-data/'\n",
    "    model_root = '/content/drive/MyDrive/colab_data/deep-ls/'\n",
    "else:\n",
    "    data_root = '../graph-convnet-tsp/data/'\n",
    "    model_root = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np \n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from deepls.TSP2OptEnv import TSP2OptMultiEnv, TSP2OptEnv, TSP2OptEnvBase, TSP2OptState\n",
    "\n",
    "font = cv2.FONT_HERSHEY_COMPLEX_SMALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepls.agent import AverageStateRewardBaselineAgent, GreedyAgent\n",
    "from torch import nn\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL SPECIFICATION\n",
    "PROBLEM_SZ = 20\n",
    "MODEL_CKPT=f'{model_root}/model-15-layer-RGCN-20-nodes-51999-val-0.016.ckpt'\n",
    "NUM_GREEDY_POSTROC_STEPS = 5\n",
    "# NUMBER OF SAMPLES\n",
    "NUM_INSTANCE_EVAL = 3\n",
    "NUM_SAMPLES_EVAL = 1\n",
    "MINIBATCH_SZ = 1\n",
    "# Rendering settings\n",
    "RENDER = True\n",
    "NUM_RENDER = 5\n",
    "RENDER_EDGE_MARGINALS = False\n",
    "RENDER_OPTIMAL_TOUR = True\n",
    "if RENDER:\n",
    "    NUM_INSTANCE_EVAL=NUM_RENDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TSP2OptMultiEnv(\n",
    "    max_num_steps=PROBLEM_SZ, \n",
    "    num_nodes=PROBLEM_SZ, \n",
    "    data_f=f'{data_root}/tsp{PROBLEM_SZ}_test_concorde.txt', \n",
    "    num_samples_per_batch=MINIBATCH_SZ,\n",
    "    same_instance_per_batch=True,\n",
    "    shuffle_data=True, \n",
    "    ret_log_tour_len=False,\n",
    "    ret_opt_tour=True\n",
    ")\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_config = {\n",
    "    'replay_buffer_size': 3,\n",
    "    'minibatch_sz': 1,\n",
    "    'batch_sz': 1,\n",
    "    'policy_optimize_every': 2,\n",
    "    'critic_optimize_every': 1,\n",
    "    'model': {   \n",
    "        \"voc_edges_in\": 3,\n",
    "        \"hidden_dim\": 128,\n",
    "        \"num_layers\": 15,\n",
    "        \"mlp_layers\": 3,\n",
    "        \"aggregation\": \"mean\",\n",
    "        \"node_dim\": 2,\n",
    "        'dont_optimize_policy_steps': 1000,\n",
    "        'value_net_type': 'normal'\n",
    "    },\n",
    "    'optim': {\n",
    "        'step_size': 1e-7, \n",
    "        'step_size_critic': 2e-5,\n",
    "        'beta_m': 0.9, \n",
    "        'beta_v': 0.999,\n",
    "        'epsilon': 1e-8\n",
    "    },\n",
    "    'device': 'cuda'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepls.solver import greedy_postproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AverageStateRewardBaselineAgent() # GreedyAgent()\n",
    "agent.agent_init(agent_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.load(MODEL_CKPT, init_config=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_opt_gaps = []\n",
    "all_opt_gaps_pre = []\n",
    "all_tour_lens = []\n",
    "all_opts = []\n",
    "all_states = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(NUM_INSTANCE_EVAL):\n",
    "    \n",
    "    tour_lens = []\n",
    "    opts = []\n",
    "    opt_gaps_pre = []\n",
    "    opt_gaps = []\n",
    "    state_list = [[] for _ in range(env.envs[0].max_num_steps + 2)] # includes post-proc states\n",
    "\n",
    "    agent.set_eval()\n",
    "    agent.set_greedy(False)\n",
    "    pbar = tqdm(range(NUM_SAMPLES_EVAL // MINIBATCH_SZ))\n",
    "    env.reset(fetch_next=True)\n",
    "    for episode in pbar:\n",
    "        env.reset(fetch_next=False)\n",
    "        states = env.get_state()\n",
    "        if RENDER and len(all_states) < NUM_RENDER:\n",
    "            state_list[env.envs[0].cur_step].extend(copy.deepcopy(states))\n",
    "        actions = agent.agent_start(states)\n",
    "        while True:\n",
    "            # Take a random action\n",
    "            rets = env.step(actions)\n",
    "            states = [ret[0] for ret in rets]\n",
    "            rewards = [ret[1] for ret in rets]\n",
    "            dones = [ret[2] for ret in rets]\n",
    "            if RENDER and len(all_states) < NUM_RENDER:\n",
    "                state_list[env.envs[0].cur_step].extend(copy.deepcopy(states))\n",
    "\n",
    "            if dones[0] == True:\n",
    "                agent.agent_end(rewards)\n",
    "                opt_gaps_pre.extend(\n",
    "                    [(state[1].tour_len / state[0].opt_tour_len) - 1. for state in states]\n",
    "                )\n",
    "                post_proc_states = greedy_postproc(states, num_postproc_steps=NUM_GREEDY_POSTROC_STEPS)\n",
    "                if RENDER and len(all_states) < NUM_RENDER:\n",
    "                    state_list[env.envs[0].cur_step + 1].extend(copy.deepcopy(post_proc_states))\n",
    "                tour_lens.extend([state[1].tour_len for state in post_proc_states])\n",
    "                opts.extend([state[0].opt_tour_len for state in post_proc_states])\n",
    "                opt_gaps.extend(\n",
    "                    [(state[1].tour_len / state[0].opt_tour_len) - 1. for state in post_proc_states]\n",
    "                )\n",
    "                break\n",
    "            else:\n",
    "                actions = agent.agent_step(rewards, states)\n",
    "    all_opt_gaps.append(opt_gaps)\n",
    "    all_opt_gaps_pre.append(opt_gaps_pre)\n",
    "    all_tour_lens.append(tour_lens)\n",
    "    all_opts.append(opts)\n",
    "    if RENDER and len(all_states) < NUM_RENDER:\n",
    "        all_states.append(state_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_samples = np.argmin(all_opt_gaps, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from deepls.gcn_model import model_input_from_states\n",
    "from deepls.graph_utils import tour_nodes_to_W\n",
    "from deepls.plot_utils import plot_tsp_heatmap\n",
    "\n",
    "def plot_action_heatmap(W_pred, x_coord, W_val, W):\n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    a = f.add_subplot(111)\n",
    "    plot_tsp_heatmap(a, x_coord, W_val, W_pred, W=W, thres=0.)\n",
    "    f.canvas.draw()\n",
    "    img = np.frombuffer(f.canvas.tostring_rgb(), dtype=np.uint8)\n",
    "    img = img.reshape(f.canvas.get_width_height()[::-1] + (3,))\n",
    "    plt.close(f)\n",
    "    return img\n",
    "\n",
    "def plot_edge_marginals(net, input_state, device):\n",
    "    best_states = [input_state[1]]\n",
    "    states = [input_state[0]]\n",
    "    # cur state\n",
    "    x_edges, x_edges_values, x_nodes_coord, x_tour = list(model_input_from_states(states))\n",
    "    # best_state\n",
    "    _, _, _, x_best_tour = model_input_from_states(best_states)\n",
    "    # get x_tour_directed\n",
    "    x_tour_directed = torch.stack([\n",
    "        torch.as_tensor(tour_nodes_to_W(state.tour_nodes, directed=True))\n",
    "        for state in states\n",
    "    ], dim=0)\n",
    "\n",
    "    model_input = [x_edges, x_edges_values, x_nodes_coord, x_tour, x_best_tour, x_tour_directed]\n",
    "    model_input = [t.to(device) for t in model_input]\n",
    "    tour_logits, tour_indices_cat = net.get_tour_logits(*model_input)\n",
    "    \n",
    "    tour_logits = tour_logits.detach().cpu()\n",
    "    tour_indices_cat = tour_indices_cat.detach().cpu()\n",
    "    \n",
    "    u = tour_indices_cat[0, :, 1]\n",
    "    v = tour_indices_cat[0, :, 2]\n",
    "    x = tour_indices_cat[0, :, 4]\n",
    "    y = tour_indices_cat[0, :, 5]\n",
    "    \n",
    "    tour_probs = torch.softmax(tour_logits[:, :, 0]/2., dim=1).detach().float()\n",
    "    edge_marginals = torch.zeros_like(x_edges, dtype=float, requires_grad=False).float()\n",
    "    for p, _u, _v, _x, _y in zip(tour_probs[0], u, v, x, y):\n",
    "        edge_marginals[0, _u, _v] += p\n",
    "        edge_marginals[0, _x, _y] += p\n",
    "    \n",
    "    img = plot_action_heatmap(edge_marginals[0].numpy(), x_nodes_coord[0].numpy(), x_edges_values[0].numpy(), W=x_edges[0].numpy())\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RENDER:\n",
    "    for instance in range(len(all_states[])):\n",
    "        b = best_samples[instance]\n",
    "        instance_episode_states = all_states[instance]\n",
    "        for episode in range(len(instance_episode_states)):\n",
    "            best_sample_state = instance_episode_states[episode][b]\n",
    "            img = best_sample_state[0].render(mode='rgb_array')[:, :, [2,1,0]]\n",
    "            img_best_state = best_sample_state[1].render(mode='rgb_array')[:, :, [2,1,0]]\n",
    "            gallery = [img, img_best_state]\n",
    "            if RENDER_EDGE_MARGINALS:\n",
    "                img_edge_marginals = plot_edge_marginals(agent.net, best_sample_state, agent.device)\n",
    "            if RENDER_OPTIMAL_TOUR:\n",
    "                opt_state = TSP2OptState(\n",
    "                    best_sample_state[0].nodes_coord,\n",
    "                    best_sample_state[0].edge_weights,\n",
    "                    best_sample_state[0].opt_tour,\n",
    "                    best_sample_state[0].opt_tour_len\n",
    "                )\n",
    "                img_opt_tour = opt_state.render(mode='rgb_array')[:, :, [2,1,0]]\n",
    "                gallery.append(img_opt_tour)\n",
    "            img = np.concatenate(gallery, axis=1)\n",
    "            img = Image.fromarray(img)\n",
    "            img.save(f'{model_root}/renders/renders-tsp-{PROBLEM_SZ}-opt-viz/render_instance_{instance:03d}_ep_{episode:03d}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_opt_gaps = np.min(all_opt_gaps, axis=1)\n",
    "best_opt_gaps_pre = np.min(all_opt_gaps_pre, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_opt_gaps = np.array(all_opt_gaps)\n",
    "all_opt_gaps_pre = np.array(all_opt_gaps_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples_to_consider = [1, 10, 20, 50, 100]\n",
    "mean_best_opt_gaps = []\n",
    "mean_best_opt_gaps_pre = []\n",
    "for n in num_samples_to_consider:\n",
    "    mean_best_opt_gaps.append(\n",
    "        np.mean(np.min(all_opt_gaps[:, :n], axis=1))\n",
    "    )\n",
    "    mean_best_opt_gaps_pre.append(\n",
    "        np.mean(np.min(all_opt_gaps_pre[:, :n], axis=1))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(num_samples_to_consider, mean_best_opt_gaps, '-o')\n",
    "plt.plot(num_samples_to_consider, mean_best_opt_gaps_pre, '-o')\n",
    "plt.grid()\n",
    "plt.title(f'optimality gap vs samples for tsp n={PROBLEM_SZ}')\n",
    "plt.savefig(f'{model_root}/sample-efficiency-tsp-{PROBLEM_SZ}.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.001754596578996385, 0.022474331142738297)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(best_opt_gaps), np.mean(best_opt_gaps_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
